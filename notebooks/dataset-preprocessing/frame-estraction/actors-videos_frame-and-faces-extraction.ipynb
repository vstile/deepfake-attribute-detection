{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset from the specified paths.\n",
    "# Preprocessing frames to extract faces in batch.\n",
    "\n",
    "# Updated paths to REAL and FAKE videos\n",
    "REAL_VIDEOS_PATH = \"/Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/original_sequences/actors/c40/videos\"\n",
    "FAKE_VIDEOS_PATHS = [\"/Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/videos\"]\n",
    "\n",
    "LABELS = {\"REAL\": 0, \"FAKE\": 1}\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_faces_from_video(video_path, label, cascade_classifier, frame_skip=20):\n",
    "    \"\"\"\n",
    "    Estrae i volti da un video e li salva in una cartella.\n",
    "\n",
    "    Args:\n",
    "        video_path: Percorso del video.\n",
    "        label: Etichetta del video (REAL o FAKE).\n",
    "        cascade_classifier: Classificatore di volti.\n",
    "        frame_skip: Numero di frame da saltare tra un'elaborazione e l'altra.\n",
    "    \"\"\"\n",
    "    faces = []\n",
    "    labels = []\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Errore nell'apertura del video: {video_path}\")\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    video_dir = os.path.dirname(video_path)\n",
    "    faces_output_dir = os.path.join(os.path.dirname(video_dir), \"faces\")\n",
    "    if not os.path.exists(faces_output_dir):\n",
    "        print(f\"Creazione della cartella faces: {faces_output_dir}\")\n",
    "        os.makedirs(faces_output_dir, exist_ok=True)\n",
    "    print(f\"Cartella faces confermata: {faces_output_dir}\")\n",
    "    frames_output_dir = os.path.join(os.path.dirname(video_dir), \"frames\")\n",
    "    if not os.path.exists(frames_output_dir):\n",
    "        print(f\"Creazione della cartella frames: {frames_output_dir}\")\n",
    "        os.makedirs(frames_output_dir, exist_ok=True)\n",
    "    print(f\"Cartella frames confermata: {frames_output_dir}\")\n",
    "\n",
    "    video_file_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    frame_count = 0\n",
    "    saved_frames = 0\n",
    "    saved_faces = 0\n",
    "    print(f\"Inizio elaborazione video: {video_file_name}\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        #frame_output_path = os.path.join(frames_output_dir, f\"{video_file_name}_{frame_count:03d}.jpeg\")\n",
    "        #if not cv2.imwrite(frame_output_path, frame):\n",
    "        #    print(f\"Errore nel salvataggio del frame: {frame_output_path}\")\n",
    "        saved_frames += 1\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            frame = cv2.resize(frame, (640, 480))\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces_detected = cascade_classifier.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "            for i, (x, y, w, h) in enumerate(faces_detected):\n",
    "                face = frame[y:y + h, x:x + w]\n",
    "                face_resized = cv2.resize(face, (224, 224))\n",
    "                face_output_path = os.path.join(faces_output_dir, f\"{video_file_name}_{frame_count:03d}_face{i}.jpeg\")\n",
    "                if cv2.imwrite(face_output_path, face_resized):\n",
    "                    faces.append(face_resized)\n",
    "                    labels.append(label)\n",
    "                    saved_faces += 1\n",
    "                else:\n",
    "                    print(f\"Errore nel salvataggio della faccia: {face_output_path}\")\n",
    "\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "    print(f\"Video {video_file_name} elaborato: {saved_frames} frames salvati, {saved_faces} facce salvate.\")\n",
    "    return np.array(faces), np.array(labels)\n",
    "\n",
    "def process_videos_in_batch(video_path, cascade_classifier, frame_skip=20):\n",
    "    \"\"\"\n",
    "    Processa tutti i video in batch e salva frame e volti.\n",
    "\n",
    "    Args:\n",
    "        video_path: Cartella contenente i video.\n",
    "        cascade_classifier: Classificatore di volti.\n",
    "        frame_skip: Numero di frame da saltare tra un'elaborazione e l'altra.\n",
    "    \"\"\"\n",
    "    faces = []\n",
    "    labels = []\n",
    "    video_files = sorted([f for f in os.listdir(video_path) if f.endswith('.mp4')])\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_full_path = os.path.join(video_path, video_file)\n",
    "        if os.path.isfile(video_full_path):\n",
    "            face_frames, face_labels = extract_faces_from_video(video_full_path, LABELS[\"REAL\"], cascade_classifier, frame_skip)\n",
    "            faces.extend(face_frames)\n",
    "            labels.extend(face_labels)\n",
    "    return np.array(faces), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Esegui l'elaborazione batch sui video REALI\n",
    "cascade_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "faces, labels = process_videos_in_batch(REAL_VIDEOS_PATH, cascade_classifier)\n",
    "print(f\"Elaborazione completata: {len(faces)} volti estratti da {len(os.listdir(REAL_VIDEOS_PATH))} video.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cartella faces confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/faces\n",
      "Cartella frames confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/frames\n",
      "Inizio elaborazione video: 01_02__exit_phone_room__YVGY8LOK\n",
      "Video 01_02__exit_phone_room__YVGY8LOK elaborato: 210 frames salvati, 10 facce salvate.\n",
      "Cartella faces confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/faces\n",
      "Cartella frames confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/frames\n",
      "Inizio elaborazione video: 01_02__hugging_happy__YVGY8LOK\n",
      "Video 01_02__hugging_happy__YVGY8LOK elaborato: 578 frames salvati, 18 facce salvate.\n",
      "Cartella faces confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/faces\n",
      "Cartella frames confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/frames\n",
      "Inizio elaborazione video: 01_02__meeting_serious__YVGY8LOK\n",
      "Video 01_02__meeting_serious__YVGY8LOK elaborato: 1044 frames salvati, 51 facce salvate.\n",
      "Cartella faces confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/faces\n",
      "Cartella frames confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/frames\n",
      "Inizio elaborazione video: 01_02__outside_talking_still_laughing__YVGY8LOK\n",
      "Video 01_02__outside_talking_still_laughing__YVGY8LOK elaborato: 727 frames salvati, 31 facce salvate.\n",
      "Cartella faces confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/faces\n",
      "Cartella frames confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/frames\n",
      "Inizio elaborazione video: 01_02__secret_conversation__YVGY8LOK\n",
      "Video 01_02__secret_conversation__YVGY8LOK elaborato: 905 frames salvati, 0 facce salvate.\n",
      "Cartella faces confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/faces\n",
      "Cartella frames confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/frames\n",
      "Inizio elaborazione video: 01_02__talking_against_wall__YVGY8LOK\n",
      "Video 01_02__talking_against_wall__YVGY8LOK elaborato: 841 frames salvati, 43 facce salvate.\n",
      "Cartella faces confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/faces\n",
      "Cartella frames confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/frames\n",
      "Inizio elaborazione video: 01_02__talking_angry_couch__YVGY8LOK\n",
      "Video 01_02__talking_angry_couch__YVGY8LOK elaborato: 1455 frames salvati, 61 facce salvate.\n",
      "Cartella faces confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/faces\n",
      "Cartella frames confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/frames\n",
      "Inizio elaborazione video: 01_02__walk_down_hall_angry__YVGY8LOK\n",
      "Video 01_02__walk_down_hall_angry__YVGY8LOK elaborato: 217 frames salvati, 11 facce salvate.\n",
      "Cartella faces confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/faces\n",
      "Cartella frames confermata: /Volumes/HDD2 - 12Tb/Developer/GitHub/PhD-Projects/dataset/dataset/manipulated_sequences/DeepFakeDetection/c40/frames\n",
      "Inizio elaborazione video: 01_02__walking_and_outside_surprised__YVGY8LOK\n"
     ]
    }
   ],
   "source": [
    "# Esegui l'elaborazione batch sui video FALSI\n",
    "cascade_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "for fake_path in FAKE_VIDEOS_PATHS:\n",
    "    fake_faces, fake_labels = process_videos_in_batch(fake_path, cascade_classifier)\n",
    "    print(f\"Elaborazione completata: {len(fake_faces)} volti estratti da {len(os.listdir(fake_path))} video FAKE.\")\n",
    "print(f\"Elaborazione completata: {len(faces)} volti estratti da {len(os.listdir(REAL_VIDEOS_PATH))} video.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
